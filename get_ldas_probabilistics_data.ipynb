{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Prakrut Kansara, Kris Su\n",
    "\n",
    "Description:\n",
    "\n",
    "Date created: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forecast in the past will be hindcast,\n",
    "\n",
    "few changes for the code, \n",
    "\n",
    "he only things will change is the time step: for each month in Jan 2023 up to october of 2024 hindcast going 6 months into the future. \n",
    "\n",
    "Servir project, and the dashboard, incorporate LDAS into "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to read and save forecast data ##\n",
    "## Create function to read data and save it in RAM as xarray Dataset\n",
    "def read_trim_forecast(file_path, va):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        file_path (str): directory of \n",
    "        va (str): variable we will be looking for \n",
    "\n",
    "    Return:\n",
    "        forecast_data (xarray.core.dataset.Dataset): trimmed dataset\n",
    "    \"\"\"\n",
    "    try:\n",
    "        forecast_data = xr.open_dataset(file_path)[va]\n",
    "        \n",
    "        # if initialization_date != None:\n",
    "           # forecast_data = forecast_data.sel(time=initialization_date)\n",
    "        # else:\n",
    "            #forecast_data = forecast_data.sel(time=-1)\n",
    "\n",
    "        return forecast_data\n",
    "    \n",
    "    except KeyError:\n",
    "        print(f'Variable {va} not found in dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to read and save hindcast data ##\n",
    "## Create function to read data and save it as netcdf file ##\n",
    "def read_trim_hindcast(file_path, va):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        file_path (str): file path to hindcast data\n",
    "        va (str): variable we will be looking for in the datatset\n",
    "    Returns:\n",
    "        hindcast_data (xarray.core.dataset.Dataset):\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        hindcast_data = xr.open_mfdataset(file_path)[va].chunk(dict(time=-1))\n",
    "        return hindcast_data\n",
    "    except KeyError:\n",
    "        print(f'Variable {va} not found in dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to calculate threshold for forecast categories defined by quantiles\n",
    "def get_thresh(icat, quantiles, xrds, dims=['ensemble','time']):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        icat (int): the ith category, for looping through three categories\n",
    "        quantiles (list): pre-defined boundaries for ranking\n",
    "        xrds (xarray.core.dataset.Dataset): xarray dataset of forecast \n",
    "        dims (list): get thresh for each variables for \n",
    "    \n",
    "    Returns:\n",
    "        xrds_lo (xarray.core.dataset.Dataset): lower threshold \n",
    "        xrds_hi (xarray.core.dataset.Dataset): higher threshold \n",
    "    \"\"\"\n",
    "    \n",
    "    if not all(elem in xrds.dims for elem in dims): \n",
    "        raise Exception('Some of the dimensions in {} is not present in the xr.Dataset {}'.format(dims,xrds))\n",
    "\n",
    "    else:\n",
    "        if icat == 0: # category 0\n",
    "            xrds_lo = -np.inf\n",
    "            xrds_hi = xrds.quantile(quantiles[icat],dim=dims)\n",
    "        elif icat == len(quantiles): # category MAX\n",
    "            xrds_lo = xrds.quantile(quantiles[icat-1],dim=dims) \n",
    "            xrds_hi = np.inf # the upper bound extent to positive infinite\n",
    "        else:\n",
    "            xrds_lo = xrds.quantile(quantiles[icat-1],dim=dims)\n",
    "            xrds_hi = xrds.quantile(quantiles[icat],dim=dims)\n",
    "    \n",
    "    return xrds_lo, xrds_hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to calculate probabilities for tercile categories by counting members within each category\n",
    "def calculate_probabilities(hcst, fcst, quantiles = [1/3., 2/3.]):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        hcst (xarray.core.dataset.Dataset): hindcast data\n",
    "        fcst (xarray.core.dataset.Dataset): forecast data\n",
    "        quantiles (list): pre-defined boundaries for ranking\n",
    "\n",
    "    Returns:\n",
    "        probs (xarray.core.dataset.Dataset): \n",
    "\n",
    "    \"\"\"\n",
    "    print('Computing probabilities...')\n",
    "    numcategories = len(quantiles)+1 # there are 3 categories in total\n",
    "\n",
    "    # Mask out 0 values in forecast (set to nan)\n",
    "    fcst_masked = fcst.where(fcst != 0)\n",
    "\n",
    "    l_probs=list() # initialize empty list\n",
    "    for icat in range(numcategories): # for each category\n",
    "        print(f'category={icat}')\n",
    "        h_lo, h_hi = get_thresh(icat, quantiles, hcst)\n",
    "        prob = np.logical_and(fcst_masked>h_lo, fcst_masked<=h_hi).sum('ensemble')/float(fcst_masked.sizes['ensemble'])\n",
    "        # Instead of using the coordinate 'quantile' coming from the hindcast xr.Dataset\n",
    "        # we will create a new coordinate called 'category'\n",
    "        #print(prob)\n",
    "\n",
    "        #print(prob.coords)\n",
    "\n",
    "        if 'quantile' in prob.coords:\n",
    "            prob = prob.drop_vars('quantile')\n",
    "        \n",
    "        l_probs.append(prob.assign_coords({'category':icat}))\n",
    "    \n",
    "    #print(l_probs)\n",
    "    probs = xr.concat(l_probs,dim='category')\n",
    "    # print(f'Saving {aggr} tercile probs netCDF files')\n",
    "    # probs.to_netcdf(f'{DATADIR}/{hcst_bname}.{aggr}.tercile_probs.nc')\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def calculate_two_ways_probabilities(hindcast, forecast, model, variable, initialization_date):\\n    cemaden_probs = calculate_probabilities(hindcast, forecast, quantiles=[1/2.])*100\\n\\n    if variable=='prec':\\n        cemaden_probability = xr.Dataset(data_vars = {'below_normal':(['L','Y','X'],cemaden_probs.sel(category=0)[variable].data)}, \\n                                            coords=dict(L=forecast.L.values,Y=forecast.Y.values, X=forecast.X.values), \\n                                            attrs=forecast.attrs)\\n    elif variable=='tref':\\n        cemaden_probability = xr.Dataset(data_vars = {'above_normal':(['L','Y','X'],cemaden_probs.sel(category=1)[variable].data)}, \\n                                            coords=dict(L=forecast.L.values,Y=forecast.Y.values, X=forecast.X.values), \\n                                            attrs=forecast.attrs)\\n        \\n    ## Save the forecast data to a netcdf file ##\\n    year = forecast.time.dt.year.values\\n    month = forecast.time.dt.month.values\\n    day = forecast.time.dt.day.values\\n\\n    cemaden_probability.to_netcdf(output_directory + initialization_date.replace('-','_') + '/cemaden_two_probability_' + model + '_' + variable + '_' + str(year) + '_' + str(month).zfill(2) + '_' + str(day).zfill(2) + '.nc')\\n\\n    print('CEMADEN: Two probability categories calculated and saved for NMME hindcast data for ' + model + ' for ' + variable + '!')\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Function to calculate two-category probabilities for CEMADEN ##\n",
    "## Only save the data for above normal category air temperature and below normal precipitation ##\n",
    "\n",
    "\"\"\"def calculate_two_ways_probabilities(hindcast, forecast, model, variable, initialization_date):\n",
    "    cemaden_probs = calculate_probabilities(hindcast, forecast, quantiles=[1/2.])*100\n",
    "\n",
    "    if variable=='prec':\n",
    "        cemaden_probability = xr.Dataset(data_vars = {'below_normal':(['L','Y','X'],cemaden_probs.sel(category=0)[variable].data)}, \n",
    "                                            coords=dict(L=forecast.L.values,Y=forecast.Y.values, X=forecast.X.values), \n",
    "                                            attrs=forecast.attrs)\n",
    "    elif variable=='tref':\n",
    "        cemaden_probability = xr.Dataset(data_vars = {'above_normal':(['L','Y','X'],cemaden_probs.sel(category=1)[variable].data)}, \n",
    "                                            coords=dict(L=forecast.L.values,Y=forecast.Y.values, X=forecast.X.values), \n",
    "                                            attrs=forecast.attrs)\n",
    "        \n",
    "    ## Save the forecast data to a netcdf file ##\n",
    "    year = forecast.time.dt.year.values\n",
    "    month = forecast.time.dt.month.values\n",
    "    day = forecast.time.dt.day.values\n",
    "\n",
    "    cemaden_probability.to_netcdf(output_directory + initialization_date.replace('-','_') + '/cemaden_two_probability_' + model + '_' + variable + '_' + str(year) + '_' + str(month).zfill(2) + '_' + str(day).zfill(2) + '.nc')\n",
    "\n",
    "    print('CEMADEN: Two probability categories calculated and saved for NMME hindcast data for ' + model + ' for ' + variable + '!')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_directory = rf'C:\\Users\\Kris\\Documents\\amazonforecast\\data\\hindcast'\n",
    "surface_model_file_path = workspace_directory + '/amazon_forecast/'\n",
    "forecast_data_file_path = surface_model_file_path + \"/ldas_fcst_2024_dec01.nc\"\n",
    "\n",
    "year = 2024\n",
    "month = 'dec'\n",
    "\n",
    "hindcast_data_file_path = []\n",
    "for i in range(2001, year):\n",
    "    hindcast_data_file_path.append(surface_model_file_path + os.path.join(f\"/ldas_fcst_{i}_{month}01.nc\"))\n",
    "#hindcast_data_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global variables\n",
    "surface_variable_short = ['Rainf_tavg', 'Qair_f_tavg',\n",
    "                          'Qs_tavg','Evap_tavg', 'Tair_f_tavg',\n",
    "                          'SoilMoist_inst', 'SoilTemp_inst']\n",
    "\n",
    "surface_variable_long = ['precipitation rate', 'specific humidity', 'surface runoff',\n",
    "                         'total evapotranspiration', 'avg air temperature', 'soil moisture content', 'SoilTemp inst']\n",
    "\n",
    "surface_variable_unit = {'Rainf_tavg':'mm/day', 'Qair_f_tavg':'g/kg', 'Qs_tavg':'mm/day',\n",
    "                         'Evap_tavg':'mm/day', 'Tair_f_tavg':'degree Celsius', 'SoilMoist_inst':'m^3 m-3', 'SoilTemp_inst':'degree Celsius'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precipitation rate\n",
      "Computing probabilities...\n",
      "category=0\n",
      "category=1\n",
      "category=2\n",
      "Saved probability values for Rainf_tavg!\n",
      "specific humidity\n",
      "Computing probabilities...\n",
      "category=0\n",
      "category=1\n",
      "category=2\n",
      "Saved probability values for Qair_f_tavg!\n",
      "surface runoff\n",
      "Computing probabilities...\n",
      "category=0\n",
      "category=1\n",
      "category=2\n",
      "Saved probability values for Qs_tavg!\n",
      "total evapotranspiration\n",
      "Computing probabilities...\n",
      "category=0\n",
      "category=1\n",
      "category=2\n",
      "Saved probability values for Evap_tavg!\n",
      "avg air temperature\n",
      "Computing probabilities...\n",
      "category=0\n",
      "category=1\n",
      "category=2\n",
      "Saved probability values for Tair_f_tavg!\n",
      "soil moisture content\n",
      "Computing probabilities...\n",
      "category=0\n",
      "category=1\n",
      "category=2\n",
      "Saved probability values for SoilMoist_inst!\n",
      "SoilTemp inst\n",
      "Computing probabilities...\n",
      "category=0\n",
      "category=1\n",
      "category=2\n",
      "Saved probability values for SoilTemp_inst!\n"
     ]
    }
   ],
   "source": [
    "for variable, variable_longname in zip(surface_variable_short, surface_variable_long):\n",
    "    \n",
    "    \n",
    "    print(variable_longname)\n",
    "\n",
    "    hindcast = read_trim_hindcast(hindcast_data_file_path, va=variable)\n",
    "\n",
    "    initialization_date = '2024-12-31'\n",
    "    forecast  = read_trim_forecast(forecast_data_file_path, variable)\n",
    "\n",
    "    probs = calculate_probabilities(hindcast, forecast) *100\n",
    "\n",
    "    max_prob = probs.max(dim='category')\n",
    "    mask = probs != max_prob\n",
    "    probs_with_nan = xr.where(mask, np.nan, probs)\n",
    "\n",
    "    file_savepath = './get_ldas_probabilistics_output' + '/prob_' + initialization_date.replace('-','_')\n",
    "    #create_directory(file_savepath)\n",
    "\n",
    "    # \n",
    "    if variable in ['SoilMoist_inst', 'SoilTemp_inst']: \n",
    "        probs_with_nan.to_netcdf(file_savepath + '_tercile_probability_max_' + str(variable) + '.nc')\n",
    "    else: \n",
    "        probs_with_nan.to_netcdf(file_savepath + '_tercile_probability_max_' + str(variable) + '_lvl_0' + '.nc')\n",
    "\n",
    "    print('Saved probability values for ' + str(variable) + '!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
